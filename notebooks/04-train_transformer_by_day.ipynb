{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-11 12:42:25.978897: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-09-11 12:42:26.002557: I tensorflow/core/platform/cpu_feature_guard.cc:183] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-11 12:42:27.435789: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:1013] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-11 12:42:27.436030: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:1013] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-11 12:42:27.436082: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:1013] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: sparse_operation_kit is imported\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base has been moved to tensorflow.python.trackable.base. The old module will be deleted in version 2.11.\n",
      "[SOK INFO] Import /usr/local/lib/python3.8/dist-packages/merlin_sok-1.2.0-py3.8-linux-x86_64.egg/sparse_operation_kit/lib/libsok_experiment.so\n",
      "[SOK INFO] Import /usr/local/lib/python3.8/dist-packages/merlin_sok-1.2.0-py3.8-linux-x86_64.egg/sparse_operation_kit/lib/libsok_experiment.so\n",
      "[SOK INFO] Initialize finished, communication tool: horovod\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-11 12:42:27.681891: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:1013] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-11 12:42:27.682043: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:1013] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-11 12:42:27.682095: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:1013] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-11 12:42:27.964081: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:1013] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-11 12:42:27.964212: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:1013] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-11 12:42:27.964268: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:1013] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-11 12:42:27.964307: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2023-09-11 12:42:27.964330: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1638] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6011 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "from transformers4rec import torch as tr\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import nvtabular as nvt\n",
    "import cudf\n",
    "import config\n",
    "import os\n",
    "# ignore warnings\n",
    "from merlin.core.dispatch import get_lib\n",
    "from merlin.schema.tags import Tags\n",
    "\n",
    "import time\n",
    "import merlin.models.tf as mm\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from merlin.schema.tags import Tags\n",
    "from nvtabular.ops import *\n",
    "\n",
    "from merlin.schema.tags import Tags\n",
    "from merlin.io.dataset import Dataset\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = os.path.join(config.data_final,'time',)\n",
    "train = Dataset(os.path.join(config.data_final,'transformer4rec','train.parquet'),engine=\"parquet\",  part_size=\"1GB\")\n",
    "# valid = Dataset(os.path.join(config.data_final,'transformer4rec', 'valid.parquet/*.parquet'),engine=\"parquet\", part_size=\"1GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = train.schema.select_by_tag(Tags.SEQUENCE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path= os.path.join(config.data_raw_dir, 'image_embeddings_norm.parquet')\n",
    "image_embeddings = cudf.read_parquet(path)\n",
    "\n",
    "max_sequence_length, d_model = 64, 64\n",
    "# Define input module to process tabular input-features and to prepare masked inputs\n",
    "input_module = tr.TabularSequenceFeatures.from_schema(\n",
    "    schema,\n",
    "    max_sequence_length=30,\n",
    "    # continuous_projection=512,\n",
    "    # categorical_projection=256,\n",
    "    aggregation=\"concat\",\n",
    "    d_output=d_model,\n",
    "    masking=\"mlm\",\n",
    ")\n",
    "# Define Next item prediction-task \n",
    "prediction_task = tr.NextItemPredictionTask(weight_tying=True,)\n",
    "\n",
    "# # Define the config of the XLNet Transformer architecture\n",
    "transformer_config = tr.XLNetConfig.build(\n",
    "    d_model=d_model, n_head=8, n_layer=5, \n",
    ")\n",
    "\n",
    "# # Get the end-to-end model \n",
    "model = transformer_config.to_torch_model(input_module, prediction_task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path= os.path.join(config.data_raw_dir, 'image_embeddings_norm.parquet')\n",
    "image_embeddings = cudf.read_parquet(path)\n",
    "\n",
    "max_sequence_length, d_model = 64, 64\n",
    "\n",
    "# Define input module to process tabular input-features and to prepare masked inputs\n",
    "input_module = tr.TabularSequenceFeatures.from_schema(\n",
    "    schema,\n",
    "    max_sequence_length=30,\n",
    "    # continuous_projection=512,\n",
    "    # categorical_projection=256,\n",
    "    aggregation=\"concat\",\n",
    "    d_output=d_model,\n",
    "    masking=\"mlm\",\n",
    ")\n",
    "\n",
    "# Define Next item prediction-task \n",
    "prediction_task = tr.NextItemPredictionTask(weight_tying=True,)\n",
    "concat_module = tr.ConcatenateFeatures()\n",
    "projection_module = nn.Linear(d_model + image_embeddings.shape[1], d_model)\n",
    "transformer_config = tr.XLNetConfig.build(\n",
    "    d_model=d_model, n_head=8, n_layer=5, \n",
    ")\n",
    "model = transformer_config.to_torch_model(input_module, prediction_task, concat_module, projection_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = tr.trainer.T4RecTrainingArguments(\n",
    "            output_dir=\"./tmp\",\n",
    "            max_sequence_length=30,\n",
    "            data_loader_engine='merlin',\n",
    "            num_train_epochs=200, \n",
    "            dataloader_drop_last=False,\n",
    "            per_device_train_batch_size = 1024,\n",
    "            per_device_eval_batch_size = 1024,\n",
    "            learning_rate=0.0005,\n",
    "            fp16=True,\n",
    "            report_to = [],\n",
    "            logging_steps=200\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuda_amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "trainer = tr.Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    schema=schema,\n",
    "    compute_metrics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 40960\n",
      "  Num Epochs = 200\n",
      "  Instantaneous batch size per device = 1024\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1024\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8000\n",
      "  Number of trainable parameters = 19128640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "Launch training for day 81 are:\n",
      "********************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [22,0,0], thread: [96,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [22,0,0], thread: [97,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [22,0,0], thread: [98,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [22,0,0], thread: [99,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [22,0,0], thread: [100,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [22,0,0], thread: [101,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [22,0,0], thread: [102,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [22,0,0], thread: [103,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [22,0,0], thread: [104,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [22,0,0], thread: [105,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [22,0,0], thread: [106,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [22,0,0], thread: [107,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [22,0,0], thread: [108,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [22,0,0], thread: [109,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [22,0,0], thread: [110,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [22,0,0], thread: [111,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [22,0,0], thread: [112,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [22,0,0], thread: [113,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [22,0,0], thread: [114,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [22,0,0], thread: [115,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [22,0,0], thread: [116,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [22,0,0], thread: [117,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [22,0,0], thread: [118,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [22,0,0], thread: [119,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [22,0,0], thread: [120,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [22,0,0], thread: [121,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [22,0,0], thread: [122,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [22,0,0], thread: [123,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [22,0,0], thread: [124,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [22,0,0], thread: [125,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [22,0,0], thread: [126,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [22,0,0], thread: [127,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/workspace/notebooks/04-train_transformer_by_day.ipynb Cell 8\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f72656373797332332d6d65726c696e2d31227d/workspace/notebooks/04-train_transformer_by_day.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m trainer\u001b[39m.\u001b[39mtrain_dataset_or_path \u001b[39m=\u001b[39m train_paths\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f72656373797332332d6d65726c696e2d31227d/workspace/notebooks/04-train_transformer_by_day.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m trainer\u001b[39m.\u001b[39mreset_lr_scheduler()\n\u001b[0;32m---> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f72656373797332332d6d65726c696e2d31227d/workspace/notebooks/04-train_transformer_by_day.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f72656373797332332d6d65726c696e2d31227d/workspace/notebooks/04-train_transformer_by_day.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m trainer\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f72656373797332332d6d65726c696e2d31227d/workspace/notebooks/04-train_transformer_by_day.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39m# Evaluate on the following day\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/trainer.py:1543\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1538\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_wrapped \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\n\u001b[1;32m   1540\u001b[0m inner_training_loop \u001b[39m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1541\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inner_training_loop, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_batch_size, args\u001b[39m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1542\u001b[0m )\n\u001b[0;32m-> 1543\u001b[0m \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1544\u001b[0m     args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   1545\u001b[0m     resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[1;32m   1546\u001b[0m     trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[1;32m   1547\u001b[0m     ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[1;32m   1548\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/trainer.py:1791\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1789\u001b[0m         tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   1790\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1791\u001b[0m     tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_step(model, inputs)\n\u001b[1;32m   1793\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   1794\u001b[0m     args\u001b[39m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1795\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1796\u001b[0m     \u001b[39mand\u001b[39;00m (torch\u001b[39m.\u001b[39misnan(tr_loss_step) \u001b[39mor\u001b[39;00m torch\u001b[39m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1797\u001b[0m ):\n\u001b[1;32m   1798\u001b[0m     \u001b[39m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1799\u001b[0m     tr_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tr_loss \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/trainer.py:2539\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2536\u001b[0m     \u001b[39mreturn\u001b[39;00m loss_mb\u001b[39m.\u001b[39mreduce_mean()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m   2538\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 2539\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_loss(model, inputs)\n\u001b[1;32m   2541\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mn_gpu \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   2542\u001b[0m     loss \u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mmean()  \u001b[39m# mean() to average on multi-gpu parallel training\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers4rec/torch/trainer.py:323\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[39mOverriding :obj:`Trainer.compute_loss()`\u001b[39;00m\n\u001b[1;32m    318\u001b[0m \u001b[39mTo allow for passing the targets to the model's forward method\u001b[39;00m\n\u001b[1;32m    319\u001b[0m \u001b[39mHow the loss is computed by Trainer. By default, all Transformers4Rec models return\u001b[39;00m\n\u001b[1;32m    320\u001b[0m \u001b[39ma dictionary of three elements {'loss', 'predictions', and 'labels}\u001b[39;00m\n\u001b[1;32m    321\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    322\u001b[0m inputs, targets \u001b[39m=\u001b[39m inputs\n\u001b[0;32m--> 323\u001b[0m outputs \u001b[39m=\u001b[39m model(inputs, targets\u001b[39m=\u001b[39;49mtargets, training\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    324\u001b[0m \u001b[39m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m    325\u001b[0m \u001b[39m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m    326\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mpast_index \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers4rec/torch/model/base.py:560\u001b[0m, in \u001b[0;36mModel.forward\u001b[0;34m(self, inputs, targets, training, testing, **kwargs)\u001b[0m\n\u001b[1;32m    558\u001b[0m predictions \u001b[39m=\u001b[39m {}\n\u001b[1;32m    559\u001b[0m \u001b[39mfor\u001b[39;00m i, head \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mheads):\n\u001b[0;32m--> 560\u001b[0m     head_output \u001b[39m=\u001b[39m head(\n\u001b[1;32m    561\u001b[0m         inputs,\n\u001b[1;32m    562\u001b[0m         call_body\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    563\u001b[0m         targets\u001b[39m=\u001b[39;49mtargets,\n\u001b[1;32m    564\u001b[0m         training\u001b[39m=\u001b[39;49mtraining,\n\u001b[1;32m    565\u001b[0m         testing\u001b[39m=\u001b[39;49mtesting,\n\u001b[1;32m    566\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    567\u001b[0m     )\n\u001b[1;32m    568\u001b[0m     labels\u001b[39m.\u001b[39mupdate(head_output[\u001b[39m\"\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m    569\u001b[0m     predictions\u001b[39m.\u001b[39mupdate(head_output[\u001b[39m\"\u001b[39m\u001b[39mpredictions\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers4rec/torch/model/base.py:382\u001b[0m, in \u001b[0;36mHead.forward\u001b[0;34m(self, body_outputs, training, testing, targets, call_body, top_k, **kwargs)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers4rec\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mprediction_task\u001b[39;00m \u001b[39mimport\u001b[39;00m NextItemPredictionTask\n\u001b[1;32m    381\u001b[0m \u001b[39mif\u001b[39;00m call_body:\n\u001b[0;32m--> 382\u001b[0m     body_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbody(body_outputs, training\u001b[39m=\u001b[39;49mtraining, testing\u001b[39m=\u001b[39;49mtesting, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    384\u001b[0m \u001b[39mif\u001b[39;00m training \u001b[39mor\u001b[39;00m testing:\n\u001b[1;32m    385\u001b[0m     losses \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers4rec/config/schema.py:50\u001b[0m, in \u001b[0;36mSchemaMixin.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     48\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_schema()\n\u001b[0;32m---> 50\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers4rec/torch/block/base.py:256\u001b[0m, in \u001b[0;36mSequentialBlock.forward\u001b[0;34m(self, input, training, testing, **kwargs)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mtraining\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m inspect\u001b[39m.\u001b[39msignature(module\u001b[39m.\u001b[39mforward)\u001b[39m.\u001b[39mparameters:\n\u001b[1;32m    255\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mtesting\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m inspect\u001b[39m.\u001b[39msignature(module\u001b[39m.\u001b[39mforward)\u001b[39m.\u001b[39mparameters:\n\u001b[0;32m--> 256\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m, training\u001b[39m=\u001b[39;49mtraining, testing\u001b[39m=\u001b[39;49mtesting)\n\u001b[1;32m    257\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39m, training\u001b[39m=\u001b[39mtraining)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers4rec/config/schema.py:50\u001b[0m, in \u001b[0;36mSchemaMixin.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     48\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_schema()\n\u001b[0;32m---> 50\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers4rec/torch/tabular/base.py:392\u001b[0m, in \u001b[0;36mTabularModule.__call__\u001b[0;34m(self, inputs, pre, post, merge_with, aggregation, *args, **kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpre_forward(inputs, transformations\u001b[39m=\u001b[39mpre)\n\u001b[1;32m    391\u001b[0m \u001b[39m# This will call the `forward` method implemented by the super class.\u001b[39;00m\n\u001b[0;32m--> 392\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(inputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)  \u001b[39m# noqa\u001b[39;00m\n\u001b[1;32m    394\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(outputs, \u001b[39mdict\u001b[39m):\n\u001b[1;32m    395\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpost_forward(\n\u001b[1;32m    396\u001b[0m         outputs, transformations\u001b[39m=\u001b[39mpost, merge_with\u001b[39m=\u001b[39mmerge_with, aggregation\u001b[39m=\u001b[39maggregation\n\u001b[1;32m    397\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers4rec/torch/features/sequence.py:259\u001b[0m, in \u001b[0;36mTabularSequenceFeatures.forward\u001b[0;34m(self, inputs, training, testing, **kwargs)\u001b[0m\n\u001b[1;32m    256\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maggregation(outputs)\n\u001b[1;32m    258\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprojection_module:\n\u001b[0;32m--> 259\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprojection_module(outputs)\n\u001b[1;32m    261\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmasking:\n\u001b[1;32m    262\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmasking(\n\u001b[1;32m    263\u001b[0m         outputs,\n\u001b[1;32m    264\u001b[0m         item_ids\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_merge[\u001b[39m\"\u001b[39m\u001b[39mcategorical_module\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mitem_seq,\n\u001b[1;32m    265\u001b[0m         training\u001b[39m=\u001b[39mtraining,\n\u001b[1;32m    266\u001b[0m         testing\u001b[39m=\u001b[39mtesting,\n\u001b[1;32m    267\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers4rec/config/schema.py:50\u001b[0m, in \u001b[0;36mSchemaMixin.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     48\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_schema()\n\u001b[0;32m---> 50\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers4rec/torch/block/base.py:252\u001b[0m, in \u001b[0;36mSequentialBlock.forward\u001b[0;34m(self, input, training, testing, **kwargs)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[39mif\u001b[39;00m i \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    251\u001b[0m     filtered_kwargs \u001b[39m=\u001b[39m filter_kwargs(kwargs, module, cascade_kwargs_if_possible\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> 252\u001b[0m     \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfiltered_kwargs)\n\u001b[1;32m    254\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mtraining\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m inspect\u001b[39m.\u001b[39msignature(module\u001b[39m.\u001b[39mforward)\u001b[39m.\u001b[39mparameters:\n\u001b[1;32m    255\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mtesting\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m inspect\u001b[39m.\u001b[39msignature(module\u001b[39m.\u001b[39mforward)\u001b[39m.\u001b[39mparameters:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers4rec/config/schema.py:50\u001b[0m, in \u001b[0;36mSchemaMixin.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     48\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_schema()\n\u001b[0;32m---> 50\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers4rec/torch/block/base.py:260\u001b[0m, in \u001b[0;36mSequentialBlock.forward\u001b[0;34m(self, input, training, testing, **kwargs)\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39m, training\u001b[39m=\u001b[39mtraining)\n\u001b[1;32m    259\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 260\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    262\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`"
     ]
    }
   ],
   "source": [
    "start_time_window_index = 81\n",
    "final_time_window_index = 104\n",
    "import glob\n",
    "import os\n",
    "import config\n",
    "\n",
    "train_window = 3\n",
    "for time_index in range(start_time_window_index, final_time_window_index - train_window + 1):\n",
    "\n",
    "    # Set data \n",
    "    time_index_train = time_index\n",
    "    time_index_eval = time_index + train_window\n",
    "\n",
    "    # train paths for time_index time_index+1 time_index+2\n",
    "    # eval paths for time_index+3\n",
    "    train_paths = []\n",
    "    for i in range(time_index,time_index + train_window):\n",
    "        train_paths.append(os.path.join(config.data_final,'time', f\"{i}/train.parquet\"))\n",
    "\n",
    "    # train_paths = glob.glob(os.path.join(config.data_final,'time', f\"{time_index_train}/train.parquet\"))\n",
    "    eval_paths = glob.glob(os.path.join(config.data_final,'time' , f\"{time_index_eval}/valid.parquet\"))\n",
    "\n",
    "    # Train on day related to time_index \n",
    "    print('*'*20)\n",
    "    print(\"Launch training for day %s are:\" %time_index)\n",
    "    print('*'*20 + '\\n')\n",
    "    trainer.train_dataset_or_path = train_paths\n",
    "    trainer.reset_lr_scheduler()\n",
    "    trainer.train()\n",
    "    trainer.state.global_step +=1\n",
    "    # Evaluate on the following day\n",
    "    trainer.eval_dataset_or_path = eval_paths\n",
    "    train_metrics = trainer.evaluate(metric_key_prefix='eval')\n",
    "    print('*'*20)\n",
    "    print(\"Eval results for day %s are:\\t\" %time_index_eval)\n",
    "    print('\\n' + '*'*20 + '\\n')\n",
    "    for key in sorted(train_metrics.keys()):\n",
    "        print(\" %s = %s\" % (key, str(train_metrics[key]))) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 18432\n",
      "  Num Epochs = 50\n",
      "  Instantaneous batch size per device = 1024\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1024\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 900\n",
      "  Number of trainable parameters = 4590016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***** Launch training for day 81: *****\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='72' max='900' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 72/900 00:07 < 01:31, 9.08 it/s, Epoch 3.94/50]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/workspace/notebooks/04-train_transformer_by_day.ipynb Cell 11\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f72656373797332332d6d65726c696e2d31227d/workspace/notebooks/04-train_transformer_by_day.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers4rec\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexamples_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m fit_and_evaluate\n\u001b[0;32m----> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f72656373797332332d6d65726c696e2d31227d/workspace/notebooks/04-train_transformer_by_day.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m OT_results \u001b[39m=\u001b[39m fit_and_evaluate(trainer, start_time_index\u001b[39m=\u001b[39;49m\u001b[39m81\u001b[39;49m , end_time_index\u001b[39m=\u001b[39;49m\u001b[39m103\u001b[39;49m ,input_dir\u001b[39m=\u001b[39;49m\u001b[39mdir\u001b[39;49m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers4rec/torch/utils/examples_utils.py:77\u001b[0m, in \u001b[0;36mfit_and_evaluate\u001b[0;34m(trainer, start_time_index, end_time_index, input_dir)\u001b[0m\n\u001b[1;32m     75\u001b[0m trainer\u001b[39m.\u001b[39mtrain_dataset_or_path \u001b[39m=\u001b[39m train_paths\n\u001b[1;32m     76\u001b[0m trainer\u001b[39m.\u001b[39mreset_lr_scheduler()\n\u001b[0;32m---> 77\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n\u001b[1;32m     79\u001b[0m \u001b[39m# 3. Evaluate on valid data of time_index+1\u001b[39;00m\n\u001b[1;32m     80\u001b[0m trainer\u001b[39m.\u001b[39meval_dataset_or_path \u001b[39m=\u001b[39m eval_paths\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/trainer.py:1543\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1538\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_wrapped \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\n\u001b[1;32m   1540\u001b[0m inner_training_loop \u001b[39m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1541\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inner_training_loop, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_batch_size, args\u001b[39m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1542\u001b[0m )\n\u001b[0;32m-> 1543\u001b[0m \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1544\u001b[0m     args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   1545\u001b[0m     resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[1;32m   1546\u001b[0m     trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[1;32m   1547\u001b[0m     ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[1;32m   1548\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/trainer.py:1791\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1789\u001b[0m         tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   1790\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1791\u001b[0m     tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_step(model, inputs)\n\u001b[1;32m   1793\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   1794\u001b[0m     args\u001b[39m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1795\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1796\u001b[0m     \u001b[39mand\u001b[39;00m (torch\u001b[39m.\u001b[39misnan(tr_loss_step) \u001b[39mor\u001b[39;00m torch\u001b[39m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1797\u001b[0m ):\n\u001b[1;32m   1798\u001b[0m     \u001b[39m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1799\u001b[0m     tr_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tr_loss \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/trainer.py:2549\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2546\u001b[0m     loss \u001b[39m=\u001b[39m loss \u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mgradient_accumulation_steps\n\u001b[1;32m   2548\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdo_grad_scaling:\n\u001b[0;32m-> 2549\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscaler\u001b[39m.\u001b[39;49mscale(loss)\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m   2550\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_apex:\n\u001b[1;32m   2551\u001b[0m     \u001b[39mwith\u001b[39;00m amp\u001b[39m.\u001b[39mscale_loss(loss, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer) \u001b[39mas\u001b[39;00m scaled_loss:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers4rec.torch.utils.examples_utils import fit_and_evaluate\n",
    "\n",
    "OT_results = fit_and_evaluate(trainer, start_time_index=81 , end_time_index=103 ,input_dir=dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'indexed_by_time_eval_/next-item/avg_precision@10': [0.03776850923895836,\n",
       "  0.06101464107632637,\n",
       "  0.06300443410873413,\n",
       "  0.06414159387350082,\n",
       "  0.0738043487071991,\n",
       "  0.0712265744805336,\n",
       "  0.07425947487354279],\n",
       " 'indexed_by_time_eval_/next-item/avg_precision@20': [0.04034682363271713,\n",
       "  0.06427469849586487,\n",
       "  0.0656658336520195,\n",
       "  0.06738380342721939,\n",
       "  0.07703784108161926,\n",
       "  0.07450366765260696,\n",
       "  0.0775429755449295],\n",
       " 'indexed_by_time_eval_/next-item/ndcg@10': [0.050285592675209045,\n",
       "  0.07817145437002182,\n",
       "  0.08036240935325623,\n",
       "  0.08172142505645752,\n",
       "  0.09382010251283646,\n",
       "  0.09025176614522934,\n",
       "  0.09415555000305176],\n",
       " 'indexed_by_time_eval_/next-item/ndcg@20': [0.06035696342587471,\n",
       "  0.09041143208742142,\n",
       "  0.09061067551374435,\n",
       "  0.09400550276041031,\n",
       "  0.10596819967031479,\n",
       "  0.1027255728840828,\n",
       "  0.10652413964271545],\n",
       " 'indexed_by_time_eval_/next-item/recall@10': [0.09088776260614395,\n",
       "  0.13241347670555115,\n",
       "  0.13577640056610107,\n",
       "  0.13737118244171143,\n",
       "  0.15708637237548828,\n",
       "  0.15073610842227936,\n",
       "  0.15723873674869537],\n",
       " 'indexed_by_time_eval_/next-item/recall@20': [0.13067397475242615,\n",
       "  0.1810489445924759,\n",
       "  0.176335409283638,\n",
       "  0.1861516684293747,\n",
       "  0.2051714062690735,\n",
       "  0.20036806166172028,\n",
       "  0.2062099128961563]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OT_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " indexed_by_time_eval_/next-item/avg_precision@10 = 0.045750506627170937\n",
      " indexed_by_time_eval_/next-item/avg_precision@20 = 0.04888351877098498\n",
      " indexed_by_time_eval_/next-item/ndcg@10 = 0.060058122095854385\n",
      " indexed_by_time_eval_/next-item/ndcg@20 = 0.07206008599504181\n",
      " indexed_by_time_eval_/next-item/recall@10 = 0.106090246497289\n",
      " indexed_by_time_eval_/next-item/recall@20 = 0.153581236043702\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# take the average of metric values over time\n",
    "avg_results = {k: np.mean(v) for k,v in OT_results.items()}\n",
    "for key in sorted(avg_results.keys()): \n",
    "    print(\" %s = %s\" % (key, str(avg_results[key]))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " indexed_by_time_eval_/next-item/avg_precision@10 = 0.045750506627170937\n",
    " indexed_by_time_eval_/next-item/avg_precision@20 = 0.04888351877098498\n",
    " indexed_by_time_eval_/next-item/ndcg@10 = 0.060058122095854385\n",
    " indexed_by_time_eval_/next-item/ndcg@20 = 0.07206008599504181\n",
    " indexed_by_time_eval_/next-item/recall@10 = 0.106090246497289\n",
    " indexed_by_time_eval_/next-item/recall@20 = 0.153581236043702"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import cudf\n",
    "from merlin.io import Dataset\n",
    "from nvtabular import Workflow\n",
    "import numpy as np\n",
    "from merlin.systems.dag import Ensemble\n",
    "from merlin.systems.dag.ops.pytorch import PredictPyTorch\n",
    "from merlin.systems.dag.ops.workflow import TransformWorkflow\n",
    "from merlin.table import TensorTable, TorchColumn\n",
    "from merlin.table.conversions import convert_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recsys_trainer.load_model_trainer_states_from_checkpoint(os.path.join(config.notebook_dir,'tmp','checkpoint-30000'), model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cudf.read_parquet(os.path.join(config.data_final,'time','104','train.parquet'), columns=model.input_schema.column_names)\n",
    "table = TensorTable.from_df(df.iloc[:100])\n",
    "for column in table.columns:\n",
    "    table[column] = convert_col(table[column], TorchColumn)\n",
    "model_input_dict = table.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topk = 20\n",
    "model.top_k = topk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "traced_model = torch.jit.trace(model, model_input_dict, strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([36727, 36914,   500,  1953,   247,  3711,  6438,  2858,  9473,    28,\n",
       "         2588, 16851,  2111,  2616, 11658,  6219, 16564,  6219, 16564, 11117,\n",
       "        11117, 11117,  4204, 16136,  3885,  1635,  1459,  1108,  4359,  9539,\n",
       "            3,    17,   706,  3446,   861,  9047,  7450,  3883,  3883,   160,\n",
       "          160, 16336,  4910, 14324,  3739,   546,   567,  4546,  2250, 15083,\n",
       "        13467, 11492,  1537,  1239,  1239,   944,  2315, 12771,   893,   612,\n",
       "           70,    70,  2487, 27922,  8766, 10352,  7715,  6364,  5302,  2568,\n",
       "         7777,  7352,  3538,  4271, 16129,    66,  7298,   752,  3675,  2445,\n",
       "        10514,  5558, 15770, 19199,   819,    36,   623, 18735, 30661,   587,\n",
       "          783,   783,   314,   314, 24511, 24511, 19199,  1638, 14497,  9960,\n",
       "          861,  1649,  7763,   355,  1814, 14598,  3883,  3531,  3829, 15639,\n",
       "        12344, 31619,  1648,  1100,  2939,  2076,  2447, 21638,  1506, 17060,\n",
       "         4564,  2221,  3141, 17022, 10833, 12649, 12649, 12278,  9597,  4406,\n",
       "        10639,  2559,  2559,  1335,  1335,  4510,  1152,  1152,  4002,  1369,\n",
       "         4510,  1602,  1118,  7302,    62,    10,  9382,  8485,  2506,  3883,\n",
       "         9973,  4461, 10234,  2186,  3043,   757,  1314,  3709,  3259,  2123,\n",
       "        12304,   155,  2204,  2204,  1054,  1054, 11460, 11460,  9477,  9382,\n",
       "         1318,  1416,  1416,  4025,  4025,    62,    62,  4572,  4572,   331,\n",
       "          331,  1852,  1852,  1521,  1521,  9382, 30791, 30791,   871, 14858,\n",
       "        14858, 10452,  1755,  9494,  8388,  8388,  9049,  9049,  9947, 21164,\n",
       "        15966, 23978, 36690, 36690,  2292,  2967,  2567, 13468,  4877, 10210,\n",
       "         4002,   706,  5596,  7121,  7121,  4738,  4708,  5827,  6965,  4910,\n",
       "         7507,   847,  4815,  4815, 27593,  1195,  4431,  2286, 12095,  2030,\n",
       "         2030,  8942,    51, 15915,  3568,    84,  2188, 10736,  9871,   107,\n",
       "          777,  8508,   626,  2713,  8462,  5197, 13780,  1987,  1754,  4549,\n",
       "         8573,  6683, 10616, 11596, 13156, 12743,  6507,  2030,  1580,  1645,\n",
       "         2421,   752,  7055,  5196,  2019,  2570,  3200,    22,    10,    10,\n",
       "        18247,  1798,  5178,  8074,  7518,  7518, 10477, 10477,  2232,   871,\n",
       "         1755,   268,  4553,  4553,  1479,  3202,  5374, 10352,   114,   820,\n",
       "         5739, 21917,  9788,  2054,  8380,  9346,  5807,  1934,  2931,   184,\n",
       "         2949,  6378,    22,  1165,   155,  5988,  5988,  1240, 18879, 14685,\n",
       "        14875,  9712,  9051,  7714, 12746,  7648,  5457,  7500,  8532,  1121,\n",
       "        11036, 12517,  9551, 12356, 21821,  9478, 17813, 12887,  1698, 11609,\n",
       "         2565,  5001,  7396, 10701,  7396, 20185, 20185,  9787, 26022, 23552,\n",
       "         8687, 16458, 17191, 10596, 20980, 20980, 20980, 20980,  1580,  7206,\n",
       "         7206,  8783, 11254,  1239, 16854, 10457,  5196,  2074, 15117,  8200,\n",
       "        17736,  2146, 11395, 15459,   752,  3265,  1188,    22,  5196,  3259,\n",
       "         1464,    29,  1714,    10,  4181,   378,   726,  7450,  2108,  1155,\n",
       "         2557,  3954,  2074,  3420,   124,  1369,  9247,  3510,   992,    27,\n",
       "         1480,  5606,  9138,  4783,  5264,  4266,  1144, 14444,  1573,  1573,\n",
       "          707,  2065,  4431,  4291,  2245, 11711,  3368,   861,  2432,  4371,\n",
       "         6807,  2211,   982,  3924,  3924,    39,    39,  1645,  7208,  2258,\n",
       "         1430,  2725,  4092,  3588,  4524,  5233,   500,   500,  3425,  1500,\n",
       "         5019,  4469,   966,  1121,  5146,  2777,  3294,  4910, 12929, 11588,\n",
       "         3446, 12691,  4338,   296,  3351, 18165, 27615,   567,     7,     7,\n",
       "           84,    84,    84, 16588,  5258, 16536, 12093,  8006, 15651, 10345,\n",
       "         3415, 10816,  2617,  6260, 16536,   987,  6176,  3076,  5229,  2614,\n",
       "         6181,  4574,   787,  7229,  3517,  4977,  8549,  1151,  3532,  5535,\n",
       "           94,  3983,  3158,  2355,  1573,  6252,  9876,  5228, 14213, 24099,\n",
       "        27436, 43498,  6101,  1703,    86,  3468,  5053, 12946,   745,   745,\n",
       "         2609,  2819,  9311,  6173,   480,  1574,  2822,  2404,  4905,  1420,\n",
       "        12691,  1673,  3359, 11137, 19196,    50,   378,   378, 18165,  1747,\n",
       "          729,   729,  9469,  3402,  1239, 15117,  3402,  1028,  4069,  2977,\n",
       "         2977,  5756,  4266, 17659, 17659,  5876, 18694, 10785,  5713,  6533,\n",
       "        13550,  1856,  3990,  5277,   576,   576,   576,  2057,  2057, 14765,\n",
       "        14765,  3156, 16590,  2519,  2315,  2355,  2355,  2012,   393,  5258,\n",
       "          247,  9127,   952,  4598, 12230,  4654, 11096, 11096,  3972,  3972,\n",
       "         3972,  1418, 10776, 10776,  5052,  5760,  2072,  4360,  3398, 12251,\n",
       "        12732,  3184,  3184, 13993,  3400, 11604, 11604,  1233, 16854, 16854,\n",
       "         8066,   108, 13404, 14395,    57,  5097,  4058,  1314,  3388,    28,\n",
       "         4290,   222,  5460,  9539,  1271,  5516,  1844, 20973,   230,  6612,\n",
       "         1854,  4571,  5146,   612,  2315,   247,    81,  9329,  6378, 19222,\n",
       "        19222, 10507,  5579,  3721, 12135, 20520,  4277,  5516,  1795,  1795,\n",
       "         3796,   705,   707,  5056,  9329,  3294,  2019,   339,  6784,  6264,\n",
       "         4202,  6838,  6838,  2478, 15435,  5101, 13340,   650,  6252,  7450,\n",
       "         7450,  1155,  2436,   459,  2019, 11157, 11126,    17,  1586, 10224,\n",
       "         6502,  3798,  2729,   434,    18,  2108,  1910,   407,  8532,   588,\n",
       "        13378, 12121,   212,  5596,  4708, 15252, 14325,  7663, 16115, 21427,\n",
       "         2899, 17920, 24628, 18272, 14687,  5699,  1028, 18272, 16492, 21425,\n",
       "          288,  7955,    59,  5888,  8577,   762,  8855,    17, 13831,   330,\n",
       "          926,  6072, 13637,  2445,  6510,  7507,   196,   706,   706,   706,\n",
       "        12304,  7160,  7160,  1525,  5302,  2717, 16566, 11603,  3900, 19267,\n",
       "        14438, 18227, 18227, 15392, 15435,  7907, 22289, 12114,  4068,  8382,\n",
       "        10712, 14454,  2912, 22289, 12114,  4068,  8382, 10712, 14454,   292,\n",
       "         3152,  9256,  1735,   228,   939,  6472, 22584, 12117,  7583,  1844,\n",
       "         5227,  5227,  7493,  1844, 21870, 21870,  5284,  7681,  7681,  3259,\n",
       "          480,  6375,    71,  4241, 12623,  4815,  1944,  1665, 21952,  1943,\n",
       "         5727,  4204, 13818, 17358, 11468,  8074,  1292,   951, 10716,  3985,\n",
       "         1970,  8397,  3283,   706,   706,  1357,  5304,  9970, 20984,  2111,\n",
       "         6821,  7121,  4196, 15686, 14683,  6378,  2834,  6683,  5632,  4406,\n",
       "        29614, 36703, 27804, 27874, 13890, 14195, 10752,  3881,  6920,  4925,\n",
       "        16848,    28,  6433,  5010,  1703,  2642, 10816,  4512,  6176,  6176,\n",
       "         3830, 22525, 20510, 20510, 11857,  3988, 21948, 14070,  8362,  7074,\n",
       "         8170, 15222, 14154,   163,  6978,  7218,  6145,    62,  3452,  1573,\n",
       "         1573,  6145, 20979,  3737, 12114,  3907,  6939, 12097,   752, 23159,\n",
       "        23159,  4783,  4783, 10052, 10052, 10052,  6141,   229,   229, 12171,\n",
       "        12740, 17097,  6877,  3115,  9108], device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_input_dict['article_id_list__values']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0,  14,  23,  32,  41,  51,  60,  67,  75,  83,  97, 103, 111, 117,\n",
       "        124, 130, 141, 148, 160, 169, 186, 204, 210, 222, 231, 238, 251, 258,\n",
       "        265, 271, 278, 291, 298, 308, 315, 322, 330, 338, 344, 352, 358, 367,\n",
       "        374, 384, 390, 397, 412, 424, 430, 440, 446, 455, 465, 473, 481, 487,\n",
       "        494, 500, 510, 522, 528, 536, 544, 551, 558, 566, 574, 591, 597, 604,\n",
       "        610, 616, 624, 630, 640, 656, 662, 668, 675, 683, 690, 696, 705, 714,\n",
       "        725, 739, 746, 757, 766, 774, 783, 798, 805, 811, 821, 829, 836, 842,\n",
       "        849, 859, 865], device='cuda:0', dtype=torch.int32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_input_dict['article_id_list__offsets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf = Workflow.load(os.path.join(config.data_final,'transformer4rec','workflow'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_op = wf.input_schema.column_names >> TransformWorkflow(wf) >> PredictPyTorch(\n",
    "    traced_model, model.input_schema, model.output_schema\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = Ensemble(torch_op, wf.input_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The registered dtype mapping for numpy doesn't contain type unknown.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/merlin/dtypes/base.py:113\u001b[0m, in \u001b[0;36mDType.to\u001b[0;34m(self, mapping_name)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 113\u001b[0m     \u001b[39mreturn\u001b[39;00m mapping\u001b[39m.\u001b[39;49mfrom_merlin(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwithout_shape)\n\u001b[1;32m    114\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/merlin/dtypes/mapping.py:162\u001b[0m, in \u001b[0;36mDTypeMapping.from_merlin\u001b[0;34m(self, merlin_dtype)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[39m# Always translate to the first external dtype in the list\u001b[39;00m\n\u001b[0;32m--> 162\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfrom_merlin_[merlin_dtype][\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mKeyError\u001b[0m: DType(name='unknown', element_type=<ElementType.Unknown: 'unknown'>, element_size=None, element_unit=None, signed=None, shape=Shape(dims=None))",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/merlin/systems/triton/export.py:52\u001b[0m, in \u001b[0;36m_convert_dtype\u001b[0;34m(dtype)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m     \u001b[39mreturn\u001b[39;00m dtype\u001b[39m.\u001b[39;49mto(\u001b[39m\"\u001b[39;49m\u001b[39mtriton\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     53\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/merlin/dtypes/base.py:115\u001b[0m, in \u001b[0;36mDType.to\u001b[0;34m(self, mapping_name)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[0;32m--> 115\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    116\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe registered dtype mapping for \u001b[39m\u001b[39m{\u001b[39;00mmapping_name\u001b[39m}\u001b[39;00m\u001b[39m doesn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt contain type \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    117\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mexc\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: The registered dtype mapping for triton doesn't contain type unknown.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/merlin/dtypes/base.py:113\u001b[0m, in \u001b[0;36mDType.to\u001b[0;34m(self, mapping_name)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 113\u001b[0m     \u001b[39mreturn\u001b[39;00m mapping\u001b[39m.\u001b[39;49mfrom_merlin(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwithout_shape)\n\u001b[1;32m    114\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/merlin/dtypes/mapping.py:162\u001b[0m, in \u001b[0;36mDTypeMapping.from_merlin\u001b[0;34m(self, merlin_dtype)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[39m# Always translate to the first external dtype in the list\u001b[39;00m\n\u001b[0;32m--> 162\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfrom_merlin_[merlin_dtype][\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mKeyError\u001b[0m: DType(name='unknown', element_type=<ElementType.Unknown: 'unknown'>, element_size=None, element_unit=None, signed=None, shape=Shape(dims=None))",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/workspace/notebooks/04-train_transformer_by_day.ipynb Cell 24\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f72656373797332332d6d65726c696e2d31227d/workspace/notebooks/04-train_transformer_by_day.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m ens_config, node_configs \u001b[39m=\u001b[39m ensemble\u001b[39m.\u001b[39;49mexport(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(config\u001b[39m.\u001b[39;49mnotebook_dir,\u001b[39m'\u001b[39;49m\u001b[39mtmp\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mfinal_model_ensamble\u001b[39;49m\u001b[39m'\u001b[39;49m))\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/merlin/systems/dag/ensemble.py:153\u001b[0m, in \u001b[0;36mEnsemble.export\u001b[0;34m(self, export_path, runtime, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mWrite out an ensemble model configuration directory. The exported\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[39mensemble is designed for use with Triton Inference Server.\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    152\u001b[0m runtime \u001b[39m=\u001b[39m runtime \u001b[39mor\u001b[39;00m TritonExecutorRuntime()\n\u001b[0;32m--> 153\u001b[0m \u001b[39mreturn\u001b[39;00m runtime\u001b[39m.\u001b[39;49mexport(\u001b[39mself\u001b[39;49m, export_path, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/merlin/systems/dag/runtimes/triton/runtime.py:133\u001b[0m, in \u001b[0;36mTritonExecutorRuntime.export\u001b[0;34m(self, ensemble, path, version, name)\u001b[0m\n\u001b[1;32m    131\u001b[0m node_id \u001b[39m=\u001b[39m node_id_table\u001b[39m.\u001b[39mget(node, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    132\u001b[0m \u001b[39mif\u001b[39;00m node_id \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 133\u001b[0m     node_config \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39;49mexport(path, node_id\u001b[39m=\u001b[39;49mnode_id, version\u001b[39m=\u001b[39;49mversion)\n\u001b[1;32m    134\u001b[0m     \u001b[39mif\u001b[39;00m node_config \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    135\u001b[0m         node_configs\u001b[39m.\u001b[39mappend(node_config)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/merlin/systems/dag/node.py:50\u001b[0m, in \u001b[0;36mInferenceNode.export\u001b[0;34m(self, output_path, node_id, version)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mexport\u001b[39m(\n\u001b[1;32m     28\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     29\u001b[0m     output_path: Union[\u001b[39mstr\u001b[39m, os\u001b[39m.\u001b[39mPathLike],\n\u001b[1;32m     30\u001b[0m     node_id: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     31\u001b[0m     version: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m,\n\u001b[1;32m     32\u001b[0m ):\n\u001b[1;32m     33\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[39m    Export a Triton config directory for this node.\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[39m        Triton model config corresponding to this node.\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mop\u001b[39m.\u001b[39;49mexport(\n\u001b[1;32m     51\u001b[0m         output_path,\n\u001b[1;32m     52\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput_schema,\n\u001b[1;32m     53\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutput_schema,\n\u001b[1;32m     54\u001b[0m         node_id\u001b[39m=\u001b[39;49mnode_id,\n\u001b[1;32m     55\u001b[0m         version\u001b[39m=\u001b[39;49mversion,\n\u001b[1;32m     56\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/merlin/systems/dag/runtimes/triton/ops/workflow.py:165\u001b[0m, in \u001b[0;36mTransformWorkflowTriton.export\u001b[0;34m(self, path, input_schema, output_schema, params, node_id, version)\u001b[0m\n\u001b[1;32m    162\u001b[0m node_export_path \u001b[39m=\u001b[39m pathlib\u001b[39m.\u001b[39mPath(path) \u001b[39m/\u001b[39m node_name\n\u001b[1;32m    163\u001b[0m node_export_path\u001b[39m.\u001b[39mmkdir(parents\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> 165\u001b[0m backend_model_config \u001b[39m=\u001b[39m _generate_nvtabular_model(\n\u001b[1;32m    166\u001b[0m     modified_workflow,\n\u001b[1;32m    167\u001b[0m     node_name,\n\u001b[1;32m    168\u001b[0m     node_export_path,\n\u001b[1;32m    169\u001b[0m     sparse_max\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mop\u001b[39m.\u001b[39;49msparse_max,\n\u001b[1;32m    170\u001b[0m     max_batch_size\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mop\u001b[39m.\u001b[39;49mmax_batch_size,\n\u001b[1;32m    171\u001b[0m     cats\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mop\u001b[39m.\u001b[39;49mcats,\n\u001b[1;32m    172\u001b[0m     conts\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mop\u001b[39m.\u001b[39;49mconts,\n\u001b[1;32m    173\u001b[0m )\n\u001b[1;32m    175\u001b[0m \u001b[39mreturn\u001b[39;00m backend_model_config\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/merlin/systems/dag/runtimes/triton/ops/workflow.py:200\u001b[0m, in \u001b[0;36m_generate_nvtabular_model\u001b[0;34m(workflow, name, output_path, version, max_batch_size, sparse_max, backend, cats, conts)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"converts a workflow to a triton mode\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[39m----------\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[39m    Names of the continuous columns\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    199\u001b[0m workflow\u001b[39m.\u001b[39msave(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(output_path, \u001b[39mstr\u001b[39m(version), \u001b[39m\"\u001b[39m\u001b[39mworkflow\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m--> 200\u001b[0m config \u001b[39m=\u001b[39m _generate_nvtabular_config(\n\u001b[1;32m    201\u001b[0m     workflow,\n\u001b[1;32m    202\u001b[0m     name,\n\u001b[1;32m    203\u001b[0m     output_path,\n\u001b[1;32m    204\u001b[0m     max_batch_size,\n\u001b[1;32m    205\u001b[0m     sparse_max\u001b[39m=\u001b[39;49msparse_max,\n\u001b[1;32m    206\u001b[0m     backend\u001b[39m=\u001b[39;49mbackend,\n\u001b[1;32m    207\u001b[0m     cats\u001b[39m=\u001b[39;49mcats,\n\u001b[1;32m    208\u001b[0m     conts\u001b[39m=\u001b[39;49mconts,\n\u001b[1;32m    209\u001b[0m )\n\u001b[1;32m    211\u001b[0m \u001b[39m# copy the model file over. note that this isn't necessary with the c++ backend, but\u001b[39;00m\n\u001b[1;32m    212\u001b[0m \u001b[39m# does provide us to use the python backend with just changing the 'backend' parameter\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[39mwith\u001b[39;00m importlib\u001b[39m.\u001b[39mresources\u001b[39m.\u001b[39mpath(\n\u001b[1;32m    214\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mmerlin.systems.triton.models\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mworkflow_model.py\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    215\u001b[0m ) \u001b[39mas\u001b[39;00m workflow_model:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/merlin/systems/dag/runtimes/triton/ops/workflow.py:255\u001b[0m, in \u001b[0;36m_generate_nvtabular_config\u001b[0;34m(workflow, name, output_path, max_batch_size, sparse_max, backend, cats, conts)\u001b[0m\n\u001b[1;32m    252\u001b[0m     config\u001b[39m.\u001b[39mparameters[\u001b[39m\"\u001b[39m\u001b[39msparse_max\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mstring_value \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mdumps(sparse_max)\n\u001b[1;32m    254\u001b[0m \u001b[39mfor\u001b[39;00m col_name, col_schema \u001b[39min\u001b[39;00m workflow\u001b[39m.\u001b[39minput_schema\u001b[39m.\u001b[39mcolumn_schemas\u001b[39m.\u001b[39mitems():\n\u001b[0;32m--> 255\u001b[0m     _add_model_param(col_schema, model_config\u001b[39m.\u001b[39;49mModelInput, config\u001b[39m.\u001b[39;49minput)\n\u001b[1;32m    257\u001b[0m \u001b[39mfor\u001b[39;00m col_name, col_schema \u001b[39min\u001b[39;00m workflow\u001b[39m.\u001b[39moutput_schema\u001b[39m.\u001b[39mcolumn_schemas\u001b[39m.\u001b[39mitems():\n\u001b[1;32m    258\u001b[0m     \u001b[39mif\u001b[39;00m sparse_max \u001b[39mand\u001b[39;00m col_name \u001b[39min\u001b[39;00m sparse_max\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m    259\u001b[0m         \u001b[39m# this assumes max_sequence_length is equal for all output columns\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/merlin/systems/triton/export.py:44\u001b[0m, in \u001b[0;36m_add_model_param\u001b[0;34m(col_schema, paramclass, params, dims)\u001b[0m\n\u001b[1;32m     37\u001b[0m     params\u001b[39m.\u001b[39mappend(\n\u001b[1;32m     38\u001b[0m         paramclass(\n\u001b[1;32m     39\u001b[0m             name\u001b[39m=\u001b[39mcol_schema\u001b[39m.\u001b[39mname \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__offsets\u001b[39m\u001b[39m\"\u001b[39m, data_type\u001b[39m=\u001b[39mmodel_config\u001b[39m.\u001b[39mTYPE_INT32, dims\u001b[39m=\u001b[39m[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m     40\u001b[0m         )\n\u001b[1;32m     41\u001b[0m     )\n\u001b[1;32m     42\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     43\u001b[0m     params\u001b[39m.\u001b[39mappend(\n\u001b[0;32m---> 44\u001b[0m         paramclass(name\u001b[39m=\u001b[39mcol_schema\u001b[39m.\u001b[39mname, data_type\u001b[39m=\u001b[39m_convert_dtype(col_schema\u001b[39m.\u001b[39;49mdtype), dims\u001b[39m=\u001b[39mdims)\n\u001b[1;32m     45\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/merlin/systems/triton/export.py:54\u001b[0m, in \u001b[0;36m_convert_dtype\u001b[0;34m(dtype)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[39mreturn\u001b[39;00m dtype\u001b[39m.\u001b[39mto(\u001b[39m\"\u001b[39m\u001b[39mtriton\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     53\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[0;32m---> 54\u001b[0m     dtype \u001b[39m=\u001b[39m dtype\u001b[39m.\u001b[39;49mto_numpy\n\u001b[1;32m     56\u001b[0m \u001b[39mif\u001b[39;00m is_string_dtype(dtype):\n\u001b[1;32m     57\u001b[0m     \u001b[39mreturn\u001b[39;00m model_config\u001b[39m.\u001b[39mTYPE_STRING\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/merlin/dtypes/base.py:121\u001b[0m, in \u001b[0;36mDType.to_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[1;32m    120\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mto_numpy\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 121\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mto(\u001b[39m\"\u001b[39;49m\u001b[39mnumpy\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/merlin/dtypes/base.py:115\u001b[0m, in \u001b[0;36mDType.to\u001b[0;34m(self, mapping_name)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[39mreturn\u001b[39;00m mapping\u001b[39m.\u001b[39mfrom_merlin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwithout_shape)\n\u001b[1;32m    114\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[0;32m--> 115\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    116\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe registered dtype mapping for \u001b[39m\u001b[39m{\u001b[39;00mmapping_name\u001b[39m}\u001b[39;00m\u001b[39m doesn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt contain type \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    117\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mexc\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: The registered dtype mapping for numpy doesn't contain type unknown."
     ]
    }
   ],
   "source": [
    "ens_config, node_configs = ensemble.export(os.path.join(config.notebook_dir,'tmp','final_model_ensamble'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
