{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-09 16:55:08.226250: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-09-09 16:55:08.251077: I tensorflow/core/platform/cpu_feature_guard.cc:183] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n",
      "[INFO]: sparse_operation_kit is imported\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base has been moved to tensorflow.python.trackable.base. The old module will be deleted in version 2.11.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-09 16:55:09.260116: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:1013] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-09 16:55:09.260346: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:1013] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-09 16:55:09.260396: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:1013] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SOK INFO] Import /usr/local/lib/python3.8/dist-packages/merlin_sok-1.2.0-py3.8-linux-x86_64.egg/sparse_operation_kit/lib/libsok_experiment.so\n",
      "[SOK INFO] Import /usr/local/lib/python3.8/dist-packages/merlin_sok-1.2.0-py3.8-linux-x86_64.egg/sparse_operation_kit/lib/libsok_experiment.so\n",
      "[SOK INFO] Initialize finished, communication tool: horovod\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-09 16:55:09.616715: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:1013] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-09 16:55:09.616839: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:1013] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-09 16:55:09.616887: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:1013] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-09 16:55:09.917177: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:1013] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-09 16:55:09.917299: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:1013] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-09 16:55:09.917352: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:1013] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-09 16:55:09.917385: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2023-09-09 16:55:09.917404: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1638] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6011 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import nvtabular as nvt\n",
    "import cudf\n",
    "import config\n",
    "import os\n",
    "# ignore warnings\n",
    "from merlin.core.dispatch import get_lib\n",
    "from merlin.schema.tags import Tags\n",
    "\n",
    "import time\n",
    "import merlin.models.tf as mm\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from merlin.schema.tags import Tags\n",
    "from nvtabular.ops import *\n",
    "\n",
    "from merlin.schema.tags import Tags\n",
    "from merlin.io.dataset import Dataset\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = nvt.Dataset(os.path.join(config.data_processed_dir,'train.parquet'),engine=\"parquet\",  part_mem_fraction=0.1)\n",
    "valid = nvt.Dataset(os.path.join(config.data_processed_dir,'valid.parquet'),engine=\"parquet\", part_mem_fraction=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# customer_features = ['customer_id', 'age', 'FN', 'Active', 'club_member_status','fashion_news_frequency']\n",
    "customer_features = ['customer_id', 'age']\n",
    "article_features = ['article_id', 'product_code', 'product_type_no', 'graphical_appearance_no', 'colour_group_code', 'perceived_colour_value_id', 'perceived_colour_master_id', 'department_no', 'index_code', 'index_group_no', 'section_no', 'garment_group_no']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = cudf.read_parquet(os.path.join(config.data_raw_dir,'articles.parquet'))[article_features]\n",
    "customers = cudf.read_parquet(os.path.join(config.data_processed_dir,'customers_enc.parquet'))[customer_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = nvt.Dataset(articles)\n",
    "customers = nvt.Dataset(customers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8231156 4453834\n"
     ]
    }
   ],
   "source": [
    "train = Dataset.merge(train, articles, on=\"article_id\", how=\"inner\")\n",
    "train = Dataset.merge(train, customers, on=\"customer_id\", how=\"inner\")\n",
    "train.to_parquet(os.path.join(config.data_processed_dir,'transformer4rec', 'train.parquet'))\n",
    "valid = Dataset.merge(valid, articles, on=\"article_id\", how=\"inner\")\n",
    "valid = Dataset.merge(valid, customers, on=\"customer_id\", how=\"inner\")\n",
    "valid.to_parquet(os.path.join(config.data_processed_dir,'transformer4rec', 'valid.parquet'))\n",
    "print(len(train.to_ddf()), len(valid.to_ddf()))\n",
    "del articles, customers, train, valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ['t_dat', 'customer_id', 'article_id', 'price', 'sales_channel_id','week']\n",
    "\n",
    "article_id = [\"article_id\"] >> Categorify() \n",
    "customer_id = [\"customer_id\"] >> Categorify() >> TagAsUserID()\n",
    "price = [\"price\"] >> LogOp() >> Normalize() >> TagAsItemFeatures() \n",
    "week_split = [\"week\"] \n",
    "time_features = [\"t_dat\"]\n",
    "session_time = (\n",
    "    time_features >> \n",
    "    nvt.ops.LambdaOp(lambda col: cudf.to_datetime(col, unit='s')) >> \n",
    "    nvt.ops.Rename(name = 'event_time_dt')\n",
    ")\n",
    "\n",
    "day = (session_time\n",
    "        >> nvt.ops.LambdaOp(lambda col: col.dt.day)\n",
    "        >> nvt.ops.Rename(name = 'day')\n",
    "        >> Categorify()\n",
    "        >> TagAsUserFeatures())\n",
    "week = (session_time\n",
    "        >> nvt.ops.LambdaOp(lambda col: col.dt.weekday)\n",
    "        >> nvt.ops.Rename(name = 'week_day')\n",
    "        >> Categorify()\n",
    "        >> TagAsUserFeatures())\n",
    "month = (session_time\n",
    "        >> nvt.ops.LambdaOp(lambda col: col.dt.month)\n",
    "        >> nvt.ops.Rename(name = 'month')\n",
    "        >> Categorify()\n",
    "        >> TagAsUserFeatures())\n",
    "year = (session_time\n",
    "        >> nvt.ops.LambdaOp(lambda col: col.dt.year)\n",
    "        >> nvt.ops.Rename(name = 'year')\n",
    "        >> Categorify()\n",
    "        >> TagAsUserFeatures())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "age =  ['age'] >>  LogOp() >> Normalize() >> TagAsUserFeatures() >> AddTags([Tags.USER,Tags.CONTINUOUS])\n",
    "# cat_customer_columns = (['FN', 'Active', 'club_member_status','fashion_news_frequency'] \n",
    "#             >> Categorify() \n",
    "#             >> TagAsUserFeatures()\n",
    "#             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_article_columns = (article_features \n",
    "              >> Categorify()  \n",
    "              >> TagAsItemFeatures())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "SESSIONS_MAX_LENGTH =30\n",
    "SESSIONS_MIN_LENGTH = 2\n",
    "\n",
    "filtered_articles = (article_id + customer_id + ['t_dat'] + price + day + week + month + year + age  + cat_article_columns + week_split\n",
    "                        >> Filter(f=lambda df: df[\"article_id\"]!=0)\n",
    ")\n",
    "groupby_features = (filtered_articles\n",
    "                    >> Groupby(\n",
    "                        groupby_cols=['customer_id', 'week'],\n",
    "                        aggs={\n",
    "                            'article_id': ['list', 'count'],\n",
    "                            'price': ['list','mean', 'std', 'max'],\n",
    "                            'product_code': ['list'],\n",
    "                            'product_type_no': ['list'],\n",
    "                            'graphical_appearance_no': ['list'],\n",
    "                            'colour_group_code': ['list'],\n",
    "                            'perceived_colour_value_id': ['list'],\n",
    "                            'perceived_colour_master_id': ['list'],\n",
    "                            'department_no': ['list'],\n",
    "                            'index_code': ['list'],\n",
    "                            'index_group_no': ['list'],\n",
    "                            'section_no': ['list'],\n",
    "                            'garment_group_no': ['list'],\n",
    "                            \n",
    "                            'day': ['list'],\n",
    "                            'week_day': ['list'],\n",
    "                            'month': ['list'],\n",
    "                            'year': ['list'],\n",
    "                        },\n",
    "                        sort_cols=[\"t_dat\"],\n",
    "                        name_sep=\"_\"\n",
    "                    )\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_columns = ['price_list',\n",
    " 'day_list',\n",
    " 'week_day_list',\n",
    " 'month_list',\n",
    " 'year_list',\n",
    " 'product_code_list',\n",
    " 'product_type_no_list',\n",
    " 'graphical_appearance_no_list',\n",
    " 'colour_group_code_list',\n",
    " 'perceived_colour_value_id_list',\n",
    " 'perceived_colour_master_id_list',\n",
    " 'department_no_list',\n",
    " 'index_code_list',\n",
    " 'index_group_no_list',\n",
    " 'section_no_list',\n",
    " 'garment_group_no_list']\n",
    "\n",
    "groupby_features_articles_id= (groupby_features['article_id_list'] \n",
    "                         >> AddTags([Tags.ITEM, Tags.ITEM_ID, Tags.SEQUENCE])\n",
    "                        )\n",
    "groupby_features_articles_features= (groupby_features[list_columns]\n",
    "                         >> AddTags([Tags.ITEM, Tags.SEQUENCE])\n",
    "                        )\n",
    "truncated_features = (groupby_features_articles_id + groupby_features_articles_features\n",
    "                      >> ListSlice(-SESSIONS_MAX_LENGTH) \n",
    "                     )\n",
    "stat_features = (groupby_features['article_id_count','price_max','price_mean','price_std']\n",
    "               >> LogOp()\n",
    "               >> Normalize()\n",
    "               >> Rename(postfix=\"_norm\")\n",
    "               >> AddTags([Tags.ITEM,Tags.CONTINUOUS])\n",
    "              )\n",
    "\n",
    "output = (groupby_features['customer_id',\"article_id_count\"] + truncated_features + stat_features + week_split\n",
    "                     >> Filter(f=lambda df: df[\"article_id_count\"] >= SESSIONS_MIN_LENGTH)\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8231156 4453834\n"
     ]
    }
   ],
   "source": [
    "train = nvt.Dataset(os.path.join(config.data_processed_dir,'transformer4rec', 'train.parquet'),engine=\"parquet\",)\n",
    "valid = nvt.Dataset(os.path.join(config.data_processed_dir,'transformer4rec', 'valid.parquet'),engine=\"parquet\")\n",
    "print(len(train.to_ddf()), len(valid.to_ddf()))\n",
    "wf = nvt.Workflow(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1576278 868810\n"
     ]
    }
   ],
   "source": [
    "train = wf.fit_transform(train)\n",
    "valid = wf.transform(valid)\n",
    "print(len(train.to_ddf()), len(valid.to_ddf()))\n",
    "# train.regenerate_dataset(os.path.join(config.data_final,'transformer4rec', 'train.parquet'),part_size=\"500MiB\", file_size=\"500MiB\")\n",
    "# valid.regenerate_dataset(os.path.join(config.data_final,'transformer4rec', 'valid.parquet'),part_size=\"500MiB\", file_size=\"500MiB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_parquet(os.path.join(config.data_final,'transformer4rec', 'train.parquet'))\n",
    "valid.to_parquet(os.path.join(config.data_final,'transformer4rec', 'valid.parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>article_id_count</th>\n",
       "      <th>article_id_list</th>\n",
       "      <th>price_list</th>\n",
       "      <th>day_list</th>\n",
       "      <th>week_day_list</th>\n",
       "      <th>month_list</th>\n",
       "      <th>year_list</th>\n",
       "      <th>product_code_list</th>\n",
       "      <th>product_type_no_list</th>\n",
       "      <th>...</th>\n",
       "      <th>department_no_list</th>\n",
       "      <th>index_code_list</th>\n",
       "      <th>index_group_no_list</th>\n",
       "      <th>section_no_list</th>\n",
       "      <th>garment_group_no_list</th>\n",
       "      <th>article_id_count_norm</th>\n",
       "      <th>price_max_norm</th>\n",
       "      <th>price_mean_norm</th>\n",
       "      <th>price_std_norm</th>\n",
       "      <th>week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[1731, 16470, 1676]</td>\n",
       "      <td>[0.4938197731971741, -0.5464950203895569, -0.1...</td>\n",
       "      <td>[5, 5, 5]</td>\n",
       "      <td>[5, 5, 5]</td>\n",
       "      <td>[10, 10, 10]</td>\n",
       "      <td>[4, 4, 4]</td>\n",
       "      <td>[113, 9240, 1301]</td>\n",
       "      <td>[4, 56, 5]</td>\n",
       "      <td>...</td>\n",
       "      <td>[9, 247, 28]</td>\n",
       "      <td>[3, 12, 3]</td>\n",
       "      <td>[3, 7, 3]</td>\n",
       "      <td>[3, 45, 7]</td>\n",
       "      <td>[10, 11, 9]</td>\n",
       "      <td>0.016249</td>\n",
       "      <td>0.244905</td>\n",
       "      <td>0.095169</td>\n",
       "      <td>0.084031</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>[1126, 3468, 8556, 151, 2055]</td>\n",
       "      <td>[-0.9365506768226624, -0.35728418827056885, 0....</td>\n",
       "      <td>[21, 21, 21, 21, 21]</td>\n",
       "      <td>[3, 3, 3, 3, 3]</td>\n",
       "      <td>[7, 7, 7, 7, 7]</td>\n",
       "      <td>[3, 3, 3, 3, 3]</td>\n",
       "      <td>[17, 1468, 3083, 95, 1417]</td>\n",
       "      <td>[6, 8, 18, 9, 5]</td>\n",
       "      <td>...</td>\n",
       "      <td>[7, 22, 43, 7, 7]</td>\n",
       "      <td>[3, 3, 4, 3, 3]</td>\n",
       "      <td>[3, 3, 4, 3, 3]</td>\n",
       "      <td>[3, 7, 4, 3, 3]</td>\n",
       "      <td>[3, 3, 14, 3, 3]</td>\n",
       "      <td>0.696710</td>\n",
       "      <td>-0.003786</td>\n",
       "      <td>-0.673464</td>\n",
       "      <td>-0.065536</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>[22, 31635, 72, 145, 145, 786, 7522, 26482, 137]</td>\n",
       "      <td>[-0.13971909880638123, -0.33306726813316345, 0...</td>\n",
       "      <td>[21, 21, 21, 21, 21, 21, 21, 21, 21]</td>\n",
       "      <td>[9, 9, 9, 9, 9, 9, 9, 9, 9]</td>\n",
       "      <td>[6, 6, 6, 6, 6, 6, 6, 6, 6]</td>\n",
       "      <td>[3, 3, 3, 3, 3, 3, 3, 3, 3]</td>\n",
       "      <td>[82, 11727, 35, 31, 31, 631, 3095, 8905, 4]</td>\n",
       "      <td>[11, 60, 11, 13, 13, 9, 17, 4, 13]</td>\n",
       "      <td>...</td>\n",
       "      <td>[3, 180, 3, 3, 3, 6, 11, 174, 3]</td>\n",
       "      <td>[5, 8, 5, 5, 5, 4, 3, 10, 5]</td>\n",
       "      <td>[3, 6, 3, 3, 3, 4, 3, 7, 3]</td>\n",
       "      <td>[5, 39, 5, 5, 5, 9, 3, 46, 5]</td>\n",
       "      <td>[7, 11, 7, 7, 7, 5, 8, 22, 7]</td>\n",
       "      <td>1.553989</td>\n",
       "      <td>0.486868</td>\n",
       "      <td>-0.246169</td>\n",
       "      <td>0.141382</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>[39575, 26482, 4110, 72, 1086, 23096, 7, 137, ...</td>\n",
       "      <td>[-0.9169830083847046, -0.33306726813316345, 1....</td>\n",
       "      <td>[9, 9, 17, 17, 17, 17, 17, 17, 17]</td>\n",
       "      <td>[5, 5, 3, 3, 3, 3, 3, 3, 3]</td>\n",
       "      <td>[6, 6, 6, 6, 6, 6, 6, 6, 6]</td>\n",
       "      <td>[3, 3, 3, 3, 3, 3, 3, 3, 3]</td>\n",
       "      <td>[14163, 8905, 3129, 35, 151, 9386, 8, 4, 45]</td>\n",
       "      <td>[4, 4, 22, 11, 23, 55, 9, 13, 9]</td>\n",
       "      <td>...</td>\n",
       "      <td>[146, 174, 19, 3, 3, 127, 88, 3, 22]</td>\n",
       "      <td>[10, 10, 4, 5, 5, 10, 4, 5, 3]</td>\n",
       "      <td>[7, 7, 4, 3, 3, 7, 4, 3, 3]</td>\n",
       "      <td>[46, 46, 4, 5, 5, 30, 34, 5, 7]</td>\n",
       "      <td>[3, 22, 9, 7, 7, 22, 5, 7, 3]</td>\n",
       "      <td>1.553989</td>\n",
       "      <td>0.772106</td>\n",
       "      <td>0.176938</td>\n",
       "      <td>0.846301</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>[10, 10, 988, 988, 988, 988, 105, 66, 1631, 27...</td>\n",
       "      <td>[-0.6242952346801758, -0.6242952346801758, 0.1...</td>\n",
       "      <td>[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]</td>\n",
       "      <td>[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]</td>\n",
       "      <td>[4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]</td>\n",
       "      <td>[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]</td>\n",
       "      <td>[4, 4, 112, 112, 112, 112, 270, 163, 4, 171, 1...</td>\n",
       "      <td>[13, 13, 11, 11, 11, 11, 11, 11, 13, 13, 13, 1...</td>\n",
       "      <td>...</td>\n",
       "      <td>[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]</td>\n",
       "      <td>[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]</td>\n",
       "      <td>[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]</td>\n",
       "      <td>[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]</td>\n",
       "      <td>[7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7]</td>\n",
       "      <td>2.234450</td>\n",
       "      <td>-0.078745</td>\n",
       "      <td>-0.090086</td>\n",
       "      <td>-0.347021</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id  article_id_count  \\\n",
       "0            0                 3   \n",
       "1            0                 5   \n",
       "2            1                 9   \n",
       "3            1                 9   \n",
       "4            1                14   \n",
       "\n",
       "                                     article_id_list  \\\n",
       "0                                [1731, 16470, 1676]   \n",
       "1                      [1126, 3468, 8556, 151, 2055]   \n",
       "2   [22, 31635, 72, 145, 145, 786, 7522, 26482, 137]   \n",
       "3  [39575, 26482, 4110, 72, 1086, 23096, 7, 137, ...   \n",
       "4  [10, 10, 988, 988, 988, 988, 105, 66, 1631, 27...   \n",
       "\n",
       "                                          price_list  \\\n",
       "0  [0.4938197731971741, -0.5464950203895569, -0.1...   \n",
       "1  [-0.9365506768226624, -0.35728418827056885, 0....   \n",
       "2  [-0.13971909880638123, -0.33306726813316345, 0...   \n",
       "3  [-0.9169830083847046, -0.33306726813316345, 1....   \n",
       "4  [-0.6242952346801758, -0.6242952346801758, 0.1...   \n",
       "\n",
       "                                     day_list  \\\n",
       "0                                   [5, 5, 5]   \n",
       "1                        [21, 21, 21, 21, 21]   \n",
       "2        [21, 21, 21, 21, 21, 21, 21, 21, 21]   \n",
       "3          [9, 9, 17, 17, 17, 17, 17, 17, 17]   \n",
       "4  [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]   \n",
       "\n",
       "                                week_day_list  \\\n",
       "0                                   [5, 5, 5]   \n",
       "1                             [3, 3, 3, 3, 3]   \n",
       "2                 [9, 9, 9, 9, 9, 9, 9, 9, 9]   \n",
       "3                 [5, 5, 3, 3, 3, 3, 3, 3, 3]   \n",
       "4  [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]   \n",
       "\n",
       "                                   month_list  \\\n",
       "0                                [10, 10, 10]   \n",
       "1                             [7, 7, 7, 7, 7]   \n",
       "2                 [6, 6, 6, 6, 6, 6, 6, 6, 6]   \n",
       "3                 [6, 6, 6, 6, 6, 6, 6, 6, 6]   \n",
       "4  [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]   \n",
       "\n",
       "                                    year_list  \\\n",
       "0                                   [4, 4, 4]   \n",
       "1                             [3, 3, 3, 3, 3]   \n",
       "2                 [3, 3, 3, 3, 3, 3, 3, 3, 3]   \n",
       "3                 [3, 3, 3, 3, 3, 3, 3, 3, 3]   \n",
       "4  [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]   \n",
       "\n",
       "                                   product_code_list  \\\n",
       "0                                  [113, 9240, 1301]   \n",
       "1                         [17, 1468, 3083, 95, 1417]   \n",
       "2        [82, 11727, 35, 31, 31, 631, 3095, 8905, 4]   \n",
       "3       [14163, 8905, 3129, 35, 151, 9386, 8, 4, 45]   \n",
       "4  [4, 4, 112, 112, 112, 112, 270, 163, 4, 171, 1...   \n",
       "\n",
       "                                product_type_no_list  ...  \\\n",
       "0                                         [4, 56, 5]  ...   \n",
       "1                                   [6, 8, 18, 9, 5]  ...   \n",
       "2                 [11, 60, 11, 13, 13, 9, 17, 4, 13]  ...   \n",
       "3                   [4, 4, 22, 11, 23, 55, 9, 13, 9]  ...   \n",
       "4  [13, 13, 11, 11, 11, 11, 11, 11, 13, 13, 13, 1...  ...   \n",
       "\n",
       "                           department_no_list  \\\n",
       "0                                [9, 247, 28]   \n",
       "1                           [7, 22, 43, 7, 7]   \n",
       "2            [3, 180, 3, 3, 3, 6, 11, 174, 3]   \n",
       "3        [146, 174, 19, 3, 3, 127, 88, 3, 22]   \n",
       "4  [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]   \n",
       "\n",
       "                              index_code_list  \\\n",
       "0                                  [3, 12, 3]   \n",
       "1                             [3, 3, 4, 3, 3]   \n",
       "2                [5, 8, 5, 5, 5, 4, 3, 10, 5]   \n",
       "3              [10, 10, 4, 5, 5, 10, 4, 5, 3]   \n",
       "4  [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]   \n",
       "\n",
       "                          index_group_no_list  \\\n",
       "0                                   [3, 7, 3]   \n",
       "1                             [3, 3, 4, 3, 3]   \n",
       "2                 [3, 6, 3, 3, 3, 4, 3, 7, 3]   \n",
       "3                 [7, 7, 4, 3, 3, 7, 4, 3, 3]   \n",
       "4  [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]   \n",
       "\n",
       "                              section_no_list  \\\n",
       "0                                  [3, 45, 7]   \n",
       "1                             [3, 7, 4, 3, 3]   \n",
       "2               [5, 39, 5, 5, 5, 9, 3, 46, 5]   \n",
       "3             [46, 46, 4, 5, 5, 30, 34, 5, 7]   \n",
       "4  [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]   \n",
       "\n",
       "                        garment_group_no_list article_id_count_norm  \\\n",
       "0                                 [10, 11, 9]              0.016249   \n",
       "1                            [3, 3, 14, 3, 3]              0.696710   \n",
       "2               [7, 11, 7, 7, 7, 5, 8, 22, 7]              1.553989   \n",
       "3               [3, 22, 9, 7, 7, 22, 5, 7, 3]              1.553989   \n",
       "4  [7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7]              2.234450   \n",
       "\n",
       "   price_max_norm  price_mean_norm  price_std_norm  week  \n",
       "0        0.244905         0.095169        0.084031    61  \n",
       "1       -0.003786        -0.673464       -0.065536    61  \n",
       "2        0.486868        -0.246169        0.141382    61  \n",
       "3        0.772106         0.176938        0.846301    61  \n",
       "4       -0.078745        -0.090086       -0.347021    61  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating time-based splits: 100%|██████████| 8/8 [00:03<00:00,  2.57it/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers4rec.utils.data_utils import save_time_based_splits\n",
    "save_time_based_splits(train,\n",
    "                       output_dir=os.path.join(config.data_final,'time'),\n",
    "                       partition_col='week',\n",
    "                       timestamp_col='customer_id', \n",
    "                      )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
